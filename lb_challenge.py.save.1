import uproot
import awkward
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from matplotlib import pyplot
from sklearn.metrics import roc_curve, auc, roc_auc_score
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from sklearn.metrics import auc
import seaborn as sns
import torch
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
import torch.nn as nn
import torch.nn.functional as F
import timeit
import os
import tensorflow as tf

workpath=os.getcwd()
starttime=timeit.default_timer()
tf.debugging.set_log_device_placement(True)
file_train=uproot.open(workpath+'/'+'data/train_D02kpipi0vxVc-cont0p5.root')
file_test=uproot.open(workpath+'/'+'data/test_D02kpipi0vxVc-cont0p5.root')
tree_train=file_train['d0tree']
tree_test=file_test['d0tree']
df_train=tree_train.arrays(library="pd")
print(df_train[0:5], type(df_train))
df_test=tree_test.arrays(library="pd")
print(df_test[0:5], type(df_test))
#print('time')
#print(timeit.default_timer()-starttime)

print(tree_test.keys())
print('device name',torch.cuda.get_device_name())
#df_train=pd.DataFrame()
##tree['vcosxy'].array(library='pd')
#for j,i in enumerate(tree_train.keys()):
#    df_train[i]=list(branches_train[tree_train.keys()[j]])

df_train=df_train.drop(['vM','vpCMS','__index__'],axis=1)
print('train done')
#df_test=pd.DataFrame()
#tree['vcosxy'].array(library='pd')

#for j,i in enumerate(tree_test.keys()):
#    df_test[i]=list(branches_test[tree_test.keys()[j]])
df_test=df_test.drop(['vM','vpCMS','__index__'],axis=1)
print('test done')
X_train=df_train.drop(['isSignal'],axis=1)
y_train=df_train['isSignal']
X_test  =df_test.drop(['isSignal'],axis=1)
y_test=df_test['isSignal']

X_train=X_train.values
X_test=X_test.values
#Y_train=y_train.values
#Y_test=y_test.values
#print("size")
#print(X_train.shape)
#print(y_train.shape)
#print(X_test.shape)
#print(y_test.shape)
print(y_train[0:5])
print("xxxxxxxxxxxxx")
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

print('memory',torch.cuda.memory_allocated())

X_train=torch.from_numpy(X_train).float().cuda()
X_test=torch.from_numpy(X_test).float().cuda()
Y_train=torch.LongTensor(y_train).cuda()
Y_test=torch.LongTensor(y_test).cuda()
#Y_train=torch.from_numpy(Y_train).float().cuda()
#Y_test=torch.from_numpy(Y_test).float().cuda()
#Y_train=Y_train.view(Y_train.shape[0],1)
#Y_test=Y_test.view(Y_test.shape[0],1)

print(Y_train[0:5])

print("sdddddddddddddd")
class ANN_Model(nn.Module):
    def __init__(self,input_features=12,hidden1=12,hidden2=24,out_features=2):
        super().__init__()
        self.f_connected1=nn.Linear(input_features,hidden1)
        self.f_connected2=nn.Linear(hidden1,hidden2)
        self.out=nn.Linear(hidden2,out_features)
    def forward(self,x):
        x=F.relu(self.f_connected1(x))
        x=F.relu(self.f_connected2(x))
        #x=F.softmax(self.out(x))
        x=F.sigmoid(self.out(x))
        return x

model=ANN_Model()
model=model.cuda()
for i in model.parameters():
    print(i.is_cuda)
print('memory')
print(torch.cuda.memory_allocated())

optimizer=torch.optim.Adam(model.parameters(),lr=0.01)
loss_function=nn.CrossEntropyLoss()

epochs=1000
final_losses=[]
for i in range(epochs):
    i=i+1
    y_pred=model.forward(X_train)
    #pred.append(y_pred)
    loss=loss_function(y_pred,Y_train)
    final_losses.append(loss)
    print("Epoch number: {}  and the loss : {}".format(i,loss.item()))
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

print("startinggg")
predictions=[]
#starttime=timeit.default_timer()
#############

with torch.no_grad():
  y_predicted=model(X_test)  
  #y_predicted=y_predicted.round()
  print(y_predicted[0:10])
  print('finding max')
  y_predicted=torch.argmax(y_predicted,axis=1)
  print(y_predicted[0:5])
  import datetime
  start = datetime.datetime.now()
  y_predicted=y_predicted.cpu()
  y_predicted= y_predicted.detach().numpy()
  end=datetime.datetime.now()
  print(end-start)
  print("converted to numpy")
  print(y_predicted[0:5])
  print('numpy done')
  y_test=y_test.round()
  print("y_test")
  print(y_test[0:5])
  accu=accuracy_score(y_test,y_predicted)
  #acc=y_predicted.eq(y_test).sum() / float(y_test.shape[0])
  #print(f'accuracy={acc:.4f}')
  print('after')
  print(accu)

#with torch.no_grad():
#  for i ,data in enumerate(X_test):
#    data=data.cuda()
#    y_pred=model(data).cuda()
#    predictions.append(y_pred.argmax().item())
correct=0
#print('pred done')
#
#starttime=timeit.default_timer()
t=0
for i in range(len(y_test)):
  if y_test[i]==y_predicted[i]:
     correct+=1
  t=t+1
print('correct',correct)
ac=(correct/t)*100
#accuracy=accuracy_score(y_test,predictions)
print(ac)
print(timeit.default_timer()-starttime)
